{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Black_Scholes_financial_functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sKQ4ThxPzrd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqtZBAvkfsIN"
      },
      "source": [
        "**First clone the github repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqy9IDmrxEXF"
      },
      "source": [
        "%cd /content\n",
        "! git clone https://github.com/Tikquuss/lwd\n",
        "%cd lwd/scripts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TlN-kmNWVKb"
      },
      "source": [
        "main_path = \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9HyFdfNjYKZ"
      },
      "source": [
        "# **Set-up** \n",
        "*Once this section is configured, you can comment (optionally) the previous cell and run everything at once (Runtime -> Run all).*  \n",
        "**Once everything is executed, a csv file will be automatically created containing all the losses on the test data for each model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqMU00jD84aL"
      },
      "source": [
        "Uncomment the line corresponding to your function, and choose the value xxx accordingly:\n",
        "* For Black&Scholes, INPUT_DIM must remain at 1.\n",
        "* For Gaussian basket options, INPUT_DIM can take any integer value greater than or equal to 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49hcDUuT5EVi"
      },
      "source": [
        "f_name = \"Black&Scholes\"\n",
        "#f_name = \"Gaussian basket options\" # vary INPUT_DIM : 1,...,7,..., 20,...\n",
        "\n",
        "INPUT_DIM = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFmSnxANxVj1"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 1.x\n",
        "    %matplotlib inline\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import random\n",
        "\n",
        "from utils import plot_stat, MLP, Siren, train, test, global_stat, reshape, to_csv\n",
        "from twin_net_tf import graph, get_diffML_data_loader, BlackScholes, Bachelier, test as twin_net_tf_test \n",
        "from twin_net_tf_siren import test as twin_net_tf_test_siren"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNfsOwIODVaD"
      },
      "source": [
        "# Global\n",
        "max_epoch = 10000\n",
        "batch_sizes = [16, 64, 512, 1024, 1024] # batch_size\n",
        "nTrains = [20, 100, 1000, 10000, 100000] # number of training examples\n",
        "nTests = [10000]*5 # number of test examples\n",
        "\n",
        "train_seed, test_seed = 0, 1 # for reproducibility\n",
        "learning_rate = 3e-5\n",
        "improving_limit = float(\"inf\") # no limit\n",
        "HIDDEN_DIM = 20\n",
        "N_HIDDEN = 4\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "# MLP\n",
        "activation_function = F.softplus\n",
        "deriv_activation_function = torch.sigmoid # for twin_net_pytorch\n",
        "mlp_model_kwargs = {\"in_features\" : INPUT_DIM, # depends on the function\n",
        "                    \"hidden_features\" : HIDDEN_DIM, \n",
        "                    \"hidden_layers\" : N_HIDDEN, \n",
        "                    \"out_features\": OUTPUT_DIM, \n",
        "                    \"activation_function\" : activation_function, \n",
        "                    \"deriv_activation_function\" : deriv_activation_function,\n",
        "                   }\n",
        "\n",
        "generator_kwargs = {\"hidden_units\" : HIDDEN_DIM, \n",
        "                    \"hidden_layers\" : N_HIDDEN}\n",
        "\n",
        "# hyperparameters in the different loss functions to express a tradeoff between y loss and dy loss\n",
        "# Leave None and None instead of 1 and 1, this will be managed automatically.\n",
        "loss_config = {'alpha': None, \"beta\" : None} \n",
        "\n",
        "# twin_net\n",
        "learning_rate_schedule = [(0.0, 1.0e-8), (0.2, 0.1), (0.6, 0.01), (0.9, 1.0e-6), (1.0, 1.0e-8)]\n",
        "\n",
        "# Siren\n",
        "first_omega_0 = 30.\n",
        "hidden_omega_0 = 30.\n",
        "outermost_linear = True\n",
        "\n",
        "siren_model_kwargs = {\"in_features\" : INPUT_DIM, \n",
        "                      \"hidden_features\" : HIDDEN_DIM, \n",
        "                      \"hidden_layers\" : N_HIDDEN, \n",
        "                      \"out_features\": OUTPUT_DIM, \n",
        "                      \"outermost_linear\" : outermost_linear, \n",
        "                      \"first_omega_0\" : first_omega_0, \n",
        "                      \"hidden_omega_0\" : hidden_omega_0}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv6UAO11bXIM"
      },
      "source": [
        "# **To avoid repeating the same code too much**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6q7jea84lMm"
      },
      "source": [
        "if f_name == \"Black&Scholes\" :\n",
        "    generator = BlackScholes()\n",
        "    # for twin_net_tf\n",
        "    graph_name = \"Black & Scholes\"\n",
        "elif f_name == \"Gaussian basket options\" : \n",
        "    generator = Bachelier(n = INPUT_DIM)\n",
        "    # for twin_net_tf\n",
        "    graph_name = \"Bachelier dimension %d\" % INPUT_DIM\n",
        "    \n",
        "csv_path = os.path.join(main_path, f_name + \".csv\")\n",
        "import os\n",
        "if not os.path.exists(main_path):\n",
        "    os.makedirs(main_path)\n",
        "\n",
        "stats_dic = {}\n",
        "tests_loss = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBNSrfxEY7cT"
      },
      "source": [
        "def run_train(name, generator, with_derivative, model_class, model_kwargs, normalize, learning_rate_schedule = None):\n",
        "    \n",
        "    global nTrains, nTests, batch_sizes, train_seed, test_seed, learning_rate\n",
        "    global max_epoch, improving_limit\n",
        "    global loss_config \n",
        "\n",
        "    model_list, loss_list, stat_list = [], [], []\n",
        "    \n",
        "    for nTrain, nTest, batch_size in zip(nTrains, nTests, batch_sizes) : \n",
        "\n",
        "        train_dataloader, test_dataloader, xAxis, vegas, config = get_diffML_data_loader(\n",
        "            generator = generator, \n",
        "            nTrain = nTrain, nTest = nTest, \n",
        "            train_seed = train_seed, test_seed = test_seed, \n",
        "            batch_size = batch_size, \n",
        "            with_derivative = with_derivative,\n",
        "            normalize = normalize\n",
        "        )\n",
        "        \n",
        "        config[\"learning_rate_schedule\"] = learning_rate_schedule\n",
        "        config.update({key : value for key, value in loss_config.items() if value})\n",
        "        \n",
        "        model = model_class(**model_kwargs)\n",
        "        criterion = torch.nn.MSELoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "        model, stats, best_loss = train(name, model, train_dataloader, optimizer, criterion, config, \n",
        "                                        with_derivative, max_epoch = max_epoch, improving_limit = improving_limit)\n",
        "        \n",
        "        plot_stat(stats, with_derivative = with_derivative)\n",
        "\n",
        "        (test_loss, r_y, r_dydx), (x_list, y_list, dydx_list, y_pred_list, dydx_pred_list) = test(\n",
        "            name, model, test_dataloader, criterion, config, with_derivative\n",
        "        )\n",
        "        \n",
        "        xy = [(x[0], y[0]) for x, y in zip(x_list, y_list)]\n",
        "        xy_pred = [(x[0], y[0]) for x, y in zip(x_list, y_pred_list)]\n",
        "      \n",
        "        if with_derivative :\n",
        "            xdydx = [(x[0], y[0]) for x, y in zip(x_list, dydx_list)]\n",
        "            xdydx_pred = [(x[0], y) for x, y in zip(x_list, dydx_pred_list)]\n",
        "\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, figsize = (15,3))\n",
        "        else :\n",
        "            fig, ax1 = plt.subplots(1, 1, sharex=True, figsize = (15,3))\n",
        "\n",
        "        fig.suptitle('')\n",
        "        \n",
        "        ax1.scatter(*zip(*xy), label = \"y\")\n",
        "        ax1.scatter(*zip(*xy_pred), label = \"ypred\")\n",
        "        ax1.set(xlabel='x', ylabel='y, y_pred')\n",
        "        ax1.legend()\n",
        "        if with_derivative :\n",
        "            ax2.scatter(*zip(*xdydx), label = \"dy\")\n",
        "            ax2.scatter(*zip(*xdydx_pred), label = \"dy pred\")\n",
        "            ax2.set(xlabel='x', ylabel='dy, dy_pred')\n",
        "            ax2.legend()\n",
        "\n",
        "        model_list.append(model)\n",
        "        loss_list.append((test_loss, r_y, r_dydx))\n",
        "        stat_list.append(stats)\n",
        "        \n",
        "    return model_list, loss_list, stat_list\n",
        "\n",
        "def run_diffML_train(name, generator, generator_kwargs, show_graph_per_axis = False, input_dim = None, \n",
        "                     siren = False, normalize = True):\n",
        "    global nTrains, nTests, batch_sizes, train_seed, test_seed\n",
        "    global max_epoch\n",
        "    global first_omega_0, hidden_omega_0, outermost_linear\n",
        "\n",
        "    regressor_list, loss_list = [], []\n",
        "    ass = {}\n",
        "    ass[\"normal\"] = ass[\"differential\"] = []\n",
        "\n",
        "    for nTrain, nTest, batch_size in zip(nTrains, nTests, batch_sizes) :\n",
        "    \n",
        "        if siren :\n",
        "            dic_loss, regressor, dtrain, dtest, dydxTest, values, deltas, xAxis, vegas = twin_net_tf_test_siren(\n",
        "                  generator, [nTrain], \n",
        "                  nTrain, nTest, \n",
        "                  trainSeed = train_seed, testSeed = test_seed, weightSeed = 0, \n",
        "                  deltidx=0,\n",
        "                  generator_kwargs = generator_kwargs,\n",
        "                  epochs = max_epoch,\n",
        "                  first_omega_0 = first_omega_0, \n",
        "                  hidden_omega_0 = hidden_omega_0, \n",
        "                  outermost_linear = outermost_linear,\n",
        "                  normalize = normalize,\n",
        "                  improving_limit = improving_limit,\n",
        "                  min_batch_size = batch_size\n",
        "                  ) \n",
        "        else :\n",
        "            dic_loss, regressor, dtrain, dtest, dydxTest, values, deltas, xAxis, vegas = twin_net_tf_test(\n",
        "                  generator, [nTrain], \n",
        "                  nTrain, nTest, \n",
        "                  trainSeed = train_seed, testSeed = test_seed, weightSeed = 0, \n",
        "                  deltidx=0,\n",
        "                  generator_kwargs = generator_kwargs,\n",
        "                  normalize = normalize,\n",
        "                  epochs = max_epoch,\n",
        "                  min_batch_size = batch_size\n",
        "                  )\n",
        "        \n",
        "        plot_stat(regressor.stats[\"normal\"], with_derivative = with_derivative)\n",
        "        plot_stat(regressor.stats[\"differential\"], with_derivative = with_derivative)\n",
        "\n",
        "        yTest = dtest[1]\n",
        "        sizes = [nTrain]\n",
        "        # show predicitions\n",
        "        graph(name, values, xAxis, \"\", \"values\", yTest, [nTrain], True)\n",
        "        # show deltas\n",
        "        graph(name, deltas, xAxis, \"\", \"deltas\", dydxTest, [nTrain], True)\n",
        "\n",
        "        if show_graph_per_axis :\n",
        "            assert input_dim\n",
        "            for i in range(input_dim) :\n",
        "                xAxis  = np.array([[x[i]] for x in dtest[0]])\n",
        "                # show predicitions\n",
        "                graph(\"%s x%d vs y\" % (name, (i+1)), values, xAxis, \"\", \"values\", yTest, [nTrain], True)\n",
        "                # show deltas\n",
        "                graph(\"%s x%d vs dxdy\" % (name, (i+1)), deltas, xAxis, \"\", \"deltas\", dydxTest, [nTrain], True)\n",
        "\n",
        "        a = dic_loss['standard_loss'][\"yloss\"][-1]\n",
        "        b = dic_loss['standard_loss'][\"dyloss\"][-1]\n",
        "        normal = (a+b, a, b)\n",
        "        a = dic_loss['differential_loss'][\"yloss\"][-1]\n",
        "        b = dic_loss['differential_loss'][\"dyloss\"][-1]\n",
        "        differential = (a+b, a, b)\n",
        "        loss = {\"normal\" : normal, \"differential\" : differential}\n",
        "\n",
        "        ass[\"normal\"].append(normal)\n",
        "        ass[\"differential\"].append(differential)\n",
        "        regressor_list.append(regressor) \n",
        "        \n",
        "    return regressor_list, ass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHUXSzIuXCDy"
      },
      "source": [
        "# **1) Normal Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpFOS9gpHqeT"
      },
      "source": [
        "name = \"net\"\n",
        "with_derivative = False\n",
        "key1 = \"normal_training\"\n",
        "stats_dic[key1] = {}\n",
        "tests_loss[key1] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy8ushomH6z0"
      },
      "source": [
        "## **1.1) with MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Lday59H9DX"
      },
      "source": [
        "model_class = MLP\n",
        "key2 = \"mlp\"\n",
        "stats_dic[key1][key2] = {}\n",
        "tests_loss[key1][key2] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Es3neNrH-5A"
      },
      "source": [
        "### **1.1.1) normalize = False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRG-9QRvZFg0"
      },
      "source": [
        "key3 = \"no_normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svU65-XOICBb"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joXY5AWsIAuc"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3d-KB87IEHB"
      },
      "source": [
        "### **1.1.2) normalize = True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC1II_Q7Zbcz"
      },
      "source": [
        "key3 = \"normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5b9ECLtIGZs"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2h0Pq9SIHlB"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEdmTaWkIJhU"
      },
      "source": [
        "## **1.2) with Siren**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB_KdEgQIKuW"
      },
      "source": [
        "model_class = Siren\n",
        "key2 = \"siren\"\n",
        "stats_dic[key1][key2] = {}\n",
        "tests_loss[key1][key2] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftQxqfJkIMex"
      },
      "source": [
        "\n",
        "### **1.2.1) normalize = False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tip15lJBfVrv"
      },
      "source": [
        "key3 = \"no_normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TluF-JQuIRGA"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne7FO9AoIPgu"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9kdvurPIT4I"
      },
      "source": [
        "### **1.2.2) normalize = True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXaoW9I7f3Ph"
      },
      "source": [
        "key3 = \"normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1STRk59IWQP"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8OCWwBPH4BJ"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PQRkpuyJMHo"
      },
      "source": [
        "# **2) Sobolev Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcLKhKXeJNc6"
      },
      "source": [
        "name = \"net\"\n",
        "with_derivative = True\n",
        "key1 = \"sobolev_training\"\n",
        "stats_dic[key1] = {}\n",
        "tests_loss[key1] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vcK3ggQJRvA"
      },
      "source": [
        "## **2.1) with MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSSWBLoeJUqW"
      },
      "source": [
        "model_class = MLP\n",
        "key2 = \"mlp\"\n",
        "stats_dic[key1][key2] = {}\n",
        "tests_loss[key1][key2] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqpMThCOJXvD"
      },
      "source": [
        "### **2.1.1) normalize = False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUCfInOMdKW-"
      },
      "source": [
        "key3 = \"no_normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czss-nlhJWw4"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aWeEwGHJbrp"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxDHPUzFJdr7"
      },
      "source": [
        "### **2.1.2) normalize = True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACmIcDrSeBdp"
      },
      "source": [
        "key3 = \"normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kf7QvIsOvW7"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS-C54pjJgeJ"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtgxirLpJh-J"
      },
      "source": [
        "## **2.2) with Siren**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS3kxNbxJk3B"
      },
      "source": [
        "model_class = Siren\n",
        "key2 = \"siren\"\n",
        "stats_dic[key1][key2] = {}\n",
        "tests_loss[key1][key2] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKOUD6KXJl8i"
      },
      "source": [
        "### **2.2.1) normalize = False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-5YVjOjdjcF"
      },
      "source": [
        "key3 = \"no_normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqBU4hT7Jns0"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsvGXRu2Jpiv"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLyEvbSnJrEE"
      },
      "source": [
        "### **2.2.2) normalize = True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMm8ssj2eRGD"
      },
      "source": [
        "key3 = \"normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmUnIY06JuOM"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0Bm8xrbI_PW"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DENXzcmWQq3A"
      },
      "source": [
        "# **3) twin_net tensorflow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-gTsESWIhTM"
      },
      "source": [
        "key1 = \"twin_net_tf\"\n",
        "key1_1 = \"%s_normal\" % key1\n",
        "key1_2 = \"%s_differential\" % key1\n",
        "stats_dic[key1_1] = {}\n",
        "stats_dic[key1_2] = {}\n",
        "tests_loss[key1_1] = {}\n",
        "tests_loss[key1_2] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WSKCZr9EsKi"
      },
      "source": [
        "## **3.1) with MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Maa9ftabMzs"
      },
      "source": [
        "key2 = \"mlp\"\n",
        "stats_dic[key1_1][key2] = {}\n",
        "stats_dic[key1_2][key2] = {}\n",
        "tests_loss[key1_1][key2] = {}\n",
        "tests_loss[key1_2][key2] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_C_BLgwAtAz"
      },
      "source": [
        "### **3.1.1) normalize = False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgLXxXuiUYxf"
      },
      "source": [
        "key3 = \"no_normalize\"\n",
        "stats_dic[key1_1][key2][key3] = [None, None]\n",
        "stats_dic[key1_2][key2][key3] = [None, None]\n",
        "tests_loss[key1_1][key2][key3] = [None, None]\n",
        "tests_loss[key1_2][key2][key3] = [None, None]\n",
        "\n",
        "regressor, loss = run_diffML_train(\n",
        "              name = graph_name, \n",
        "              generator = generator, \n",
        "              generator_kwargs = generator_kwargs ,\n",
        "              show_graph_per_axis = True, \n",
        "              input_dim = INPUT_DIM,\n",
        "              normalize = False\n",
        "              )\n",
        "stats_dic[key1_1][key2][key3][0] = stats_dic[key1_1][key2][key3][1] = [r.stats[\"normal\"] for r in regressor]\n",
        "stats_dic[key1_2][key2][key3][0] = stats_dic[key1_2][key2][key3][1] = [r.stats[\"differential\"] for r in regressor]\n",
        "tests_loss[key1_1][key2][key3][0] = tests_loss[key1_1][key2][key3][1] = loss[\"normal\"]\n",
        "tests_loss[key1_2][key2][key3][0] = tests_loss[key1_2][key2][key3][1] = loss[\"differential\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXXhHIIaBdkI"
      },
      "source": [
        "### **3.1.2) normalize = True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi72PU9FBhcY"
      },
      "source": [
        "key3 = \"normalize\"\n",
        "stats_dic[key1_1][key2][key3] = [None, None]\n",
        "stats_dic[key1_2][key2][key3] = [None, None]\n",
        "tests_loss[key1_1][key2][key3] = [None, None]\n",
        "tests_loss[key1_2][key2][key3] = [None, None]\n",
        "\n",
        "regressor, loss = run_diffML_train(\n",
        "              name = graph_name, \n",
        "              generator = generator, \n",
        "              generator_kwargs = generator_kwargs ,\n",
        "              show_graph_per_axis = True, \n",
        "              input_dim = INPUT_DIM,\n",
        "              normalize = True\n",
        "              )\n",
        "\n",
        "stats_dic[key1_1][key2][key3][0] = stats_dic[key1_1][key2][key3][1] = [r.stats[\"normal\"] for r in regressor]\n",
        "stats_dic[key1_2][key2][key3][0] = stats_dic[key1_2][key2][key3][1] = [r.stats[\"differential\"] for r in regressor]\n",
        "tests_loss[key1_1][key2][key3][0] = tests_loss[key1_1][key2][key3][1] = loss[\"normal\"]\n",
        "tests_loss[key1_2][key2][key3][0] = tests_loss[key1_2][key2][key3][1] = loss[\"differential\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apPHY6DwE6kN"
      },
      "source": [
        "## **3.2) with Siren**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA3GYEhrbB2j"
      },
      "source": [
        "key2 = \"siren\"\n",
        "stats_dic[key1_1][key2] = {}\n",
        "stats_dic[key1_2][key2] = {}\n",
        "tests_loss[key1_1][key2] = {}\n",
        "tests_loss[key1_2][key2] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9GJVQHpB-MB"
      },
      "source": [
        "### **3.2.1) normalize = False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-jvlP5NE0Hh"
      },
      "source": [
        "key3 = \"no_normalize\"\n",
        "stats_dic[key1_1][key2][key3] = [None, None]\n",
        "stats_dic[key1_2][key2][key3] = [None, None]\n",
        "tests_loss[key1_1][key2][key3] = [None, None]\n",
        "tests_loss[key1_2][key2][key3] = [None, None]\n",
        "\n",
        "regressor, loss = run_diffML_train(\n",
        "              name = graph_name, \n",
        "              generator = generator, \n",
        "              generator_kwargs = generator_kwargs ,\n",
        "              show_graph_per_axis = True, \n",
        "              input_dim = INPUT_DIM,\n",
        "              siren = True, # Siren\n",
        "              normalize = False\n",
        "              )\n",
        "\n",
        "stats_dic[key1_1][key2][key3][0] = stats_dic[key1_1][key2][key3][1] = [r.stats[\"normal\"] for r in regressor]\n",
        "stats_dic[key1_2][key2][key3][0] = stats_dic[key1_2][key2][key3][1] = [r.stats[\"differential\"] for r in regressor]\n",
        "tests_loss[key1_1][key2][key3][0] = tests_loss[key1_1][key2][key3][1] = loss[\"normal\"]\n",
        "tests_loss[key1_2][key2][key3][0] = tests_loss[key1_2][key2][key3][1] = loss[\"differential\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVOEBbGWCGGS"
      },
      "source": [
        "### **3.2.2) normalize = True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH_s6qiFB14f"
      },
      "source": [
        "key3 = \"normalize\"\n",
        "stats_dic[key1_1][key2][key3] = [None, None]\n",
        "stats_dic[key1_2][key2][key3] = [None, None]\n",
        "tests_loss[key1_1][key2][key3] = [None, None]\n",
        "tests_loss[key1_2][key2][key3] = [None, None]\n",
        "\n",
        "regressor, loss = run_diffML_train(\n",
        "              name = graph_name, \n",
        "              generator = generator, \n",
        "              generator_kwargs = generator_kwargs ,\n",
        "              show_graph_per_axis = True, \n",
        "              input_dim = INPUT_DIM,\n",
        "              siren = True, # Siren\n",
        "              normalize = True\n",
        "              )\n",
        "\n",
        "stats_dic[key1_1][key2][key3][0] = stats_dic[key1_1][key2][key3][1] = [r.stats[\"normal\"] for r in regressor]\n",
        "stats_dic[key1_2][key2][key3][0] = stats_dic[key1_2][key2][key3][1] = [r.stats[\"differential\"] for r in regressor]\n",
        "tests_loss[key1_1][key2][key3][0] = tests_loss[key1_1][key2][key3][1] = loss[\"normal\"]\n",
        "tests_loss[key1_2][key2][key3][0] = tests_loss[key1_2][key2][key3][1] = loss[\"differential\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGt4_Ni8QYkR"
      },
      "source": [
        "# **4) twin_net pytorch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kV2RQ-sQaBc"
      },
      "source": [
        "name = \"twin_net\"\n",
        "with_derivative = True\n",
        "key1 = \"twin_net_pytorch\"\n",
        "stats_dic[key1] = {}\n",
        "tests_loss[key1] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZTGXBbaHVWU"
      },
      "source": [
        "## **4.1) with MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnGgTEkpHT1B"
      },
      "source": [
        "model_class = MLP\n",
        "key2 = \"mlp\"\n",
        "stats_dic[key1][key2] = {}\n",
        "tests_loss[key1][key2] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFxqwZg_HSbZ"
      },
      "source": [
        "### **4.1.1) normalize = False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIdVdVBpgIIy"
      },
      "source": [
        "key3 = \"no_normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAA2vU92HRdB"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9UiNuywHQhe"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbpHwVlDHObp"
      },
      "source": [
        "### **4.1.2) normalize = True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iT47KVRugeZp"
      },
      "source": [
        "key3 = \"normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_YlRjPsHMDM"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeIPx0HEHNLV"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = mlp_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83iFdmkTHJMO"
      },
      "source": [
        "## **4.2) with Siren**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "320GEBHaHHbP"
      },
      "source": [
        "model_class = Siren\n",
        "key2 = \"siren\"\n",
        "stats_dic[key1][key2] = {}\n",
        "tests_loss[key1][key2] = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSBlNAFOHGfo"
      },
      "source": [
        "### **4.2.1) normalize = False**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHQx_SpqguNm"
      },
      "source": [
        "key3 = \"no_normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guxLaD8SHEiV"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXDEtSLFHDNR"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = False, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2tvrwrTHAvt"
      },
      "source": [
        "### **4.2.2) normalize = True**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Z1wvbNg0aE"
      },
      "source": [
        "key3 = \"normalize\"\n",
        "stats_dic[key1][key2][key3] = [None, None]\n",
        "tests_loss[key1][key2][key3] = [None, None]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm0yhMOuG_so"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][0], stats_dic[key1][key2][key3][0] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfFb3FMrG-S6"
      },
      "source": [
        "model, tests_loss[key1][key2][key3][1], stats_dic[key1][key2][key3][1] = run_train(\n",
        "    name = name, \n",
        "    generator = generator, \n",
        "    with_derivative = with_derivative, \n",
        "    model_class = model_class, \n",
        "    model_kwargs = siren_model_kwargs,\n",
        "    normalize = True, \n",
        "    learning_rate_schedule = learning_rate_schedule)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzc9mwAUkemP"
      },
      "source": [
        "# **5) Global Stats**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p9seS5-H940"
      },
      "source": [
        "import pickle, os\n",
        "\n",
        "for nTrain, sd in reshape(dic = stats_dic, nTrains = nTrains).items() :\n",
        "    \n",
        "    print(\"nTrain %d\" % nTrain)\n",
        "\n",
        "    global_stat(stats_dic = sd, suptitle = graph_name)\n",
        "\n",
        "    file_path = os.path.join(main_path, str(nTrain) + \".pkl\")\n",
        "    pickle.dump(sd, open(file_path, 'wb'))\n",
        "    #stats_dic = pickle.load(open(file_path, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrrUsoaK4IK2"
      },
      "source": [
        "for nTrain, tl in reshape(dic = tests_loss, nTrains = nTrains).items() :\n",
        "    print(\"nTrain %d\" % nTrain)\n",
        "    rows, result = to_csv(dico = tl, csv_path = csv_path, n_samples = str(nTrain), mode='a+')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}